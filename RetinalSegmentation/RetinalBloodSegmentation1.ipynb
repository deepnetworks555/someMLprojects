{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of retinal 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ZA6DYgx2fsZc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Retinal Blood vessel segmentation by  CNN"
      ]
    },
    {
      "metadata": {
        "id": "0wDS1JENWvX2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setting up the drive"
      ]
    },
    {
      "metadata": {
        "id": "jv4OrAz_z65J",
        "colab_type": "code",
        "outputId": "507553d9-e8c0-48dd-c04f-a8138cb63136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nA9WzRodWnVT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Loading and preparing data"
      ]
    },
    {
      "metadata": {
        "id": "ahc7_iFU9Gh7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YW2skhms-Iqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_path = '/content/gdrive/My Drive/Retinal/training/'\n",
        "\n",
        "image_width = 565\n",
        "image_height = 584"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0eFTCuD-ALKz",
        "colab_type": "code",
        "outputId": "d146679f-e1d5-423d-d518-2f9c363ce831",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "img_data_path = os.path.join(data_path, 'images')\n",
        "seg_data_path = os.path.join(data_path, '1st_manual')\n",
        "\n",
        "print(img_data_path)\n",
        "print(seg_data_path)\n",
        "\n",
        "images = sorted(os.listdir(img_data_path))\n",
        "segs = sorted(os.listdir(seg_data_path))\n",
        "num_images = len(images)\n",
        "num_segs = len(segs)\n",
        "print('number of images:',num_images , num_segs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Retinal/training/images\n",
            "/content/gdrive/My Drive/Retinal/training/1st_manual\n",
            "number of images: 20 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4ajMeF0OP7ey",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imgs_array = np.ndarray((num_images, image_width, image_height), dtype=np.uint8)\n",
        "segs_array = np.ndarray((num_segs, image_width, image_height), dtype=np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pZvwNWnBP7iF",
        "colab_type": "code",
        "outputId": "6eb08347-774e-4f87-ad36-5809bd78b044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "print('Creating training images arrays...')\n",
        "n = 0\n",
        "good_imgs=[]\n",
        "for image_name in images:\n",
        "    #print('reading image %s    %d' % (image_name,n+1))\n",
        "    img = Image.open(os.path.join(img_data_path,image_name)).convert('L') \n",
        "    good_imgs.append(image_name)\n",
        "    img = np.array(img.resize((image_height,image_width)))\n",
        "    imgs_array[n] = img\n",
        "    n +=1\n",
        "\n",
        "np.save('/content/gdrive/My Drive/Retinal/training/imgs_train.npy', imgs_array[0:len(good_imgs)])\n",
        "print(len(good_imgs),imgs_array.shape)\n",
        "\n",
        "\n",
        "n = 0\n",
        "good_imgs=[]\n",
        "for image_name in segs:\n",
        "    #print('reading seg %s    %d' % (image_name,n+1))\n",
        "    img = Image.open(os.path.join(seg_data_path,image_name)).convert('L')\n",
        "    good_imgs.append(image_name)\n",
        "    img = np.array(img.resize((image_height,image_width)))\n",
        "    segs_array[n] = img\n",
        "    n +=1\n",
        "  \n",
        "np.save('/content/gdrive/My Drive/Retinal/training/seg_train.npy', segs_array[0:len(good_imgs)])\n",
        "print('finished saving image arrays.')\n",
        "\n",
        "print(segs_array.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating training images arrays...\n",
            "20 (20, 565, 584)\n",
            "finished saving image arrays.\n",
            "(20, 565, 584)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UxGRFDEiP7nK",
        "colab_type": "code",
        "outputId": "4daadf71-9298-4db8-8a6e-e5689f780d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "imgs_array[0:len(good_imgs)].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 565, 584)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "23BXUpPySmZF",
        "colab_type": "code",
        "outputId": "210330d3-bfbe-4717-bda3-85b0957af635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "img_no=10\n",
        "print(imgs_array.shape)\n",
        "w=Image.fromarray(imgs_array[img_no].reshape(image_width,image_height))\n",
        "display(w)\n",
        "\n",
        "print(imgs_array.shape)\n",
        "w=Image.fromarray(segs_array[img_no].reshape(image_width,image_height))\n",
        "display(w)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimg_no=10\\nprint(imgs_array.shape)\\nw=Image.fromarray(imgs_array[img_no].reshape(image_width,image_height))\\ndisplay(w)\\n\\nprint(imgs_array.shape)\\nw=Image.fromarray(segs_array[img_no].reshape(image_width,image_height))\\ndisplay(w)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "3Lf7eF1hXt8W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del imgs_array\n",
        "del segs_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "StM7PrJUtRdi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#making patches of size 128*128\n",
        "patch_size=128\n",
        "step_size=16\n",
        "imgs = np.load(data_path+'imgs_train.npy')\n",
        "segs = np.load(data_path+'seg_train.npy')\n",
        "\n",
        "from skimage.util.shape import view_as_windows\n",
        "\n",
        "imgs_patches = np.array([])\n",
        "segs_patches = np.array([])\n",
        "for i in range(imgs.shape[0]):\n",
        "  patches=view_as_windows(imgs[i], (patch_size, patch_size), step=step_size)\n",
        "  patches=patches.reshape(-1,patch_size,patch_size)\n",
        "  seg_pats=view_as_windows(segs[i], (patch_size, patch_size), step=step_size)\n",
        "  seg_pats=seg_pats.reshape(-1,patch_size,patch_size)\n",
        " \n",
        "  if i==0:\n",
        "    imgs_patches=patches\n",
        "    segs_patches=seg_pats\n",
        "  else:\n",
        "    imgs_patches=np.append(imgs_patches,patches,axis=0)\n",
        "    segs_patches=np.append(segs_patches,seg_pats,axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsD9ZvE-_fT1",
        "colab_type": "code",
        "outputId": "c1eb2cc7-2f93-4ca3-8ebe-e8ef88db2b96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "patches.shape, imgs_patches.shape, segs_patches.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((812, 128, 128), (16240, 128, 128), (16240, 128, 128))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "macELOZU_gLo",
        "colab_type": "code",
        "outputId": "5b2ff1a3-5da4-4c0f-b7df-83b45aa1a692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "cell_type": "code",
      "source": [
        "w=Image.fromarray(imgs_patches[190].reshape(patch_size,patch_size))\n",
        "display(w)\n",
        "w=Image.fromarray(segs_patches[190].reshape(patch_size,patch_size))\n",
        "display(w)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAcHklEQVR4nD27zZIlyY6jCYC045F1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\nKteGdQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F5AE72632B0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAADTklEQVR4nO2b23bsIAiGJSvv/8r2\nIodBBUEFnO5dr7oyHf4vCCSKAzmRA+jL6pFXDGQGKsqGhf6SFRN9NcFho0YMmL0TIwdMW7LTn7Nl\nqT8TiDYZMGKvDEJj+ZRARCgA8noFbAn6o6iYDvqNRvVRoeikzxPklFI6XSQ1446NIgZ8HJCAisPn\nWowHqknAQAe66uSA2rNlYvo9jAoCpFnNR3QQVvKAvLP0EiULA6WekAfMq3CDUF+4bjhqCqpU/Hg7\nCqDQx5MdBID0q1ALAeDl/QGowKeucCFiKU7bBTYBlxdnOovkk8oAgjBLG+sDTDGMeVQEGAThzLFf\nV2eB9LSeLeVqDywM6L1uAlUkzKCwRSkGqs8NGAqLuZVAAJx7Figak5m8KgT3FXjjGKRRhkCRBaOh\nMZbwQm6ZvqaRPghfGdUxFwxwxRQuasK6wKNMQfEE7gN4LRbRvkXMyqhFeP/aBPDZRdwF8BJsA3jG\nPoDbBRs9cBH8x1Nw52IkQFvW8uYpgJQ3xwDsD8K8GUDcyzZVy9TW/e4pCAYgPN4FCFi2pbO3MPHb\nPUYAKbErtwgHvG/Fbu0SaRxos9i6Z6ca53Xjt7Rjz4AbdxbAI1x4IYLmXRnBxwuh4YDqAOBwSEFJ\n0E8/W0fQiUZr9HaXZ5WGACqIMRCOnk6xHkB1CENA6ITMk+njANKO92icDk7BWxsGZR6r1PcaPQ3A\n6vZUtxmhA5A55BgdbkvQQaPuAxDflGNKAYBsDQ7GHv9K1tOYKZHMd775rTjmkfjNHrB+IM8ELkcw\neU6O+lrXA+yRQMNOk7RV6/5aJAQhRwAzJ/VmAHiCYX1miGmo6fe5AvD3akMwX4jAxgffXQmlYbGa\nXYvmPGJkdF0wQqGyQv+fQdsOlhqcNkG44MffnQV/AP8EQFj3nCuacR7YvDBhy2XUgcb1o1w+8jEn\nKruF+nTdHlYYPzx3RDU3dya/n3aozJ7PP1sjaC2+DQvjboX6jvCZHjsnMPLUi9OBmxXO+uSAQtvC\nBx11ygPVWT3ffaEuwDsBwXUJis+9EQgX0LvvbggtAf1Lq8AOZk3k7YTGBfUbkX1RqAkEgM+t+xDo\nOiau81DloqLL4vuc1G1BGbdQVQAEhdkxZ2zoB8MN4NsP5nKjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=128x128 at 0x7F5AE7263518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tY4F1blCXEP_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "g00cj2zqXcfI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose, \\\n",
        "                          Flatten, Dense, UpSampling2D,Dropout,BatchNormalization,Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cI80TG4IZr1-",
        "colab_type": "code",
        "outputId": "ded02227-dde4-4f62-893c-b39a0e19f0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "imgs_patches = imgs_patches[:,:,:,np.newaxis]\n",
        "segs_patches = segs_patches[:,:,:,np.newaxis]\n",
        "\n",
        "imgs_patches = imgs_patches.astype('float32')\n",
        "imgs_patches /=255.0\n",
        "segs_patches = segs_patches.astype('float32')\n",
        "segs_patches /=255.0\n",
        "\n",
        "#segs_patches=to_categorical(segs_patches, num_classes=2)\n",
        "segs_patches.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16240, 128, 128, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Ck549Odk9fTl",
        "colab_type": "code",
        "outputId": "7fa2c424-bbc6-492a-d7ea-334d2037fa3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "imgs_patches.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16240, 128, 128, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "PvP6KOucaGqW",
        "colab_type": "code",
        "outputId": "d4f10f8a-c836-4bfd-8943-e45828b171ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_imgs, valid_imgs, train_segs, valid_segs = \\\n",
        "                    train_test_split(imgs_patches, segs_patches, test_size=0.2, random_state=54)\n",
        "\n",
        "del imgs_patches\n",
        "del segs_patches\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "BR-XG0jLXprK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seedval=29\n",
        "seed(seedval*1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(seedval*2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y3690ptgsWkY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model architecture"
      ]
    },
    {
      "metadata": {
        "id": "bw0Sq6gTcjkU",
        "colab_type": "code",
        "outputId": "d0451cb5-26bb-438e-faed-4fabb7922cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "cell_type": "code",
      "source": [
        "def BN_ReLU(input_features): \n",
        "    output_features = BatchNormalization()(input_features)\n",
        "    output_features = Activation('relu')(output_features)\n",
        "    return output_features\n",
        "\n",
        "\n",
        "def Model_Architecture(input_layer):\n",
        "    initial_num_filters=16\n",
        "    input_layer = BatchNormalization()(input_layer)  #sdg \n",
        "    #in:128--out:64\n",
        "    conv1 = Conv2D(initial_num_filters * 1, (3, 3), padding=\"same\")(input_layer)\n",
        "    out = BN_ReLU(conv1) \n",
        "    out = MaxPooling2D((2, 2))(out)   #check stride? sdg\n",
        "    out = Dropout(0.2)(out)\n",
        "    #in:64--out:32\n",
        "    conv2 = Conv2D(initial_num_filters * 2, (3, 3), padding=\"same\")(out)\n",
        "    out = BN_ReLU(conv2) \n",
        "    out = MaxPooling2D((2, 2))(out)   \n",
        "    out = Dropout(0.2)(out)\n",
        "    #in:32--out:16\n",
        "    conv3 = Conv2D(initial_num_filters * 3, (3, 3), padding=\"same\")(out)\n",
        "    out = BN_ReLU(conv3) \n",
        "    out = MaxPooling2D((2, 2))(out)   \n",
        "    out = Dropout(0.2)(out)\n",
        "    #in:16--out:8\n",
        "    conv4 = Conv2D(initial_num_filters * 4, (3, 3), padding=\"same\")(out)\n",
        "    out = BN_ReLU(conv4) \n",
        "    out = MaxPooling2D((2, 2))(out)   \n",
        "    out = Dropout(0.2)(out)\n",
        "    #in:8--out:4\n",
        "    conv5 = Conv2D(initial_num_filters * 5, (3, 3), padding=\"same\")(out)\n",
        "    out = BN_ReLU(conv5) \n",
        "    out = MaxPooling2D((2, 2))(out)   \n",
        "    out = Dropout(0.2)(out)\n",
        "    #in:4--out:2\n",
        "    conv6 = Conv2D(initial_num_filters * 6, (3, 3), padding=\"same\")(out)\n",
        "    out = BN_ReLU(conv6) \n",
        "    out = MaxPooling2D((2, 2))(out)   \n",
        "    out = Dropout(0.2)(out)\n",
        "    #in:2--out:1\n",
        "    conv7 = Conv2D(initial_num_filters * 7, (3, 3), padding=\"same\")(out)\n",
        "    out = BN_ReLU(conv7) \n",
        "    out = MaxPooling2D((2, 2))(out)   \n",
        "    out = Dropout(0.2)(out)\n",
        "    \n",
        "\n",
        "    #Decoding\n",
        "    convT7 = Conv2DTranspose(initial_num_filters * 7, (3, 3), strides=(2, 2), padding=\"same\")(out)\n",
        "    convT7 = Conv2D(initial_num_filters * 7, (3, 3), padding=\"same\")(convT7)\n",
        "    out = concatenate([convT7, conv7])\n",
        "    out = BN_ReLU(out)\n",
        "    out = Dropout(0.2)(out)\n",
        "    \n",
        "    convT6 = Conv2DTranspose(initial_num_filters * 6, (3, 3), strides=(2, 2), padding=\"same\")(out)\n",
        "    convT6 = Conv2D(initial_num_filters * 6, (3, 3), padding=\"same\")(convT6)\n",
        "    out = concatenate([convT6, conv6])\n",
        "    out = BN_ReLU(out)\n",
        "    out = Dropout(0.2)(out)\n",
        "    \n",
        "    \n",
        "    convT5 = Conv2DTranspose(initial_num_filters * 5, (3, 3), strides=(2, 2), padding=\"same\")(out)\n",
        "    convT5 = Conv2D(initial_num_filters * 5, (3, 3), padding=\"same\")(convT5)\n",
        "    out = concatenate([convT5, conv5])\n",
        "    out = BN_ReLU(out)\n",
        "    out = Dropout(0.2)(out)\n",
        "\n",
        "    \n",
        "    convT4 = Conv2DTranspose(initial_num_filters * 4, (3, 3), strides=(2, 2), padding=\"same\")(out)\n",
        "    convT4 = Conv2D(initial_num_filters * 4, (3, 3), padding=\"same\")(convT4)\n",
        "    out = concatenate([convT4, conv4])\n",
        "    out = BN_ReLU(out)\n",
        "    out = Dropout(0.2)(out)\n",
        "    \n",
        "    \n",
        "    convT3 = Conv2DTranspose(initial_num_filters * 3, (3, 3), strides=(2, 2), padding=\"same\")(out)\n",
        "    convT3 = Conv2D(initial_num_filters * 3, (3, 3), padding=\"same\")(convT3)\n",
        "    out = concatenate([convT3, conv3])\n",
        "    out = BN_ReLU(out)\n",
        "    out = Dropout(0.2)(out)\n",
        "    \n",
        "    convT2 = Conv2DTranspose(initial_num_filters * 2, (3, 3), strides=(2, 2), padding=\"same\")(out)\n",
        "    convT2 = Conv2D(initial_num_filters * 2, (3, 3), padding=\"same\")(convT2)\n",
        "    out = concatenate([convT2, conv2])\n",
        "    out = BN_ReLU(out)\n",
        "    out = Dropout(0.2)(out)\n",
        "    \n",
        "    convT1 = Conv2DTranspose(initial_num_filters * 1, (3, 3), strides=(2, 2), padding=\"same\")(out)\n",
        "    convT1 = Conv2D(initial_num_filters * 1, (3, 3), padding=\"same\")(convT1)\n",
        "    out = concatenate([convT1, conv1])\n",
        "    out = BN_ReLU(out)\n",
        "    out = Dropout(0.2)(out)\n",
        "\n",
        "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(out)\n",
        "    return output_layer\n",
        "\n",
        "  \n",
        "input_layer=Input(shape=(128,128,1))\n",
        "output_layer=Model_Architecture(input_layer)\n",
        "\n",
        "model=Model(inputs=input_layer,outputs=output_layer)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8H9fzU-xK05v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fmzv40ztngkP",
        "colab_type": "code",
        "outputId": "58dad191-7942-4cc4-b5d8-f2770258ba7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3110
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 128, 128, 1)  4           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 128, 128, 16) 160         batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 128, 128, 16) 64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 128, 128, 16) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 64, 64, 16)   0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 32)   4640        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 32)   128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 32)   0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 48)   13872       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 48)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 16, 16, 48)   0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 16, 16, 64)   27712       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 8, 8, 64)     0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 8, 80)     46160       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 8, 8, 80)     320         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 80)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 80)     0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 4, 4, 80)     0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 4, 4, 96)     69216       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 4, 4, 96)     384         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 4, 4, 96)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 2, 2, 96)     0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 2, 2, 96)     0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 2, 2, 112)    96880       dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 2, 2, 112)    448         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 2, 2, 112)    0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 112)    0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 1, 1, 112)    0           max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 2, 2, 112)    113008      dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 2, 2, 112)    113008      conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2, 2, 224)    0           conv2d_8[0][0]                   \n",
            "                                                                 conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 2, 2, 224)    896         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 2, 2, 224)    0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 2, 2, 224)    0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 4, 4, 96)     193632      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 4, 4, 96)     83040       conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 4, 4, 192)    0           conv2d_9[0][0]                   \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 4, 4, 192)    768         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 4, 4, 192)    0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 4, 4, 192)    0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 8, 8, 80)     138320      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 8, 8, 80)     57680       conv2d_transpose_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 8, 160)    0           conv2d_10[0][0]                  \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 8, 8, 160)    640         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 160)    0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 8, 8, 160)    0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 16, 16, 64)   92224       dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 64)   36928       conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 16, 16, 128)  0           conv2d_11[0][0]                  \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 16, 16, 128)  0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 32, 32, 48)   55344       dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 48)   20784       conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 96)   0           conv2d_12[0][0]                  \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 96)   384         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 96)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 96)   0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 64, 64, 32)   27680       dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 64, 64, 32)   9248        conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 64, 64, 64)   0           conv2d_13[0][0]                  \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 64, 64, 64)   0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 128, 128, 16) 9232        dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 16) 2320        conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 128, 128, 32) 0           conv2d_14[0][0]                  \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 128, 128, 32) 128         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 128, 128, 32) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 128, 128, 32) 0           activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 1)  33          dropout_14[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 1,216,501\n",
            "Trainable params: 1,213,811\n",
            "Non-trainable params: 2,690\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qaqAAUdvK4GV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def focal_loss(gamma=2., alpha=.60):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        pt1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
        "        pt0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
        "        # clip to prevent NaN's and Inf's\n",
        "        pt1 = K.clip(pt1, K.epsilon(), 1-K.epsilon())\n",
        "        pt0 = K.clip(pt0, K.epsilon(), 1-K.epsilon())\n",
        "        return -K.mean(alpha * K.pow(1. - pt1, gamma) * K.log(pt1), axis=-1) \\\n",
        "               -K.mean((1-alpha) * K.pow( pt0, gamma) * K.log(1. - pt0) ,axis=-1)\n",
        "    return focal_loss_fixed\n",
        " \n",
        "#loss =[focal_loss(gamma=0.0,alpha=0.60)], 'categorical_crossentropy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9q5BXnwn3mZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(lr=0.001), loss = [focal_loss(gamma=0.1,alpha=0.60)] , metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "model_checkpoint = ModelCheckpoint(data_path+\"checkpoint/keras.model\", monitor='val_loss', save_best_only=True, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ALpTgH1aE7X",
        "colab_type": "code",
        "outputId": "3cb7aaf3-1078-4626-f2dc-180b11136f50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6891
        }
      },
      "cell_type": "code",
      "source": [
        "batchsize=64\n",
        "# we create two instances with the same arguments\n",
        "data_gen_args = dict(horizontal_flip=True,\n",
        "                     vertical_flip=True)\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "# Provide the same seed and keyword arguments to the fit and flow methods\n",
        "seed = seedval*4\n",
        "\n",
        "\n",
        "image_generator = image_datagen.flow(train_imgs, batch_size=batchsize, shuffle=True, seed=seed)\n",
        "mask_generator = mask_datagen.flow(train_segs, batch_size=batchsize, shuffle=True, seed=seed)\n",
        "\n",
        "\n",
        "# combine generators into one which yields image and masks\n",
        "train_generator = zip(image_generator, mask_generator)\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=np.ceil(len(train_imgs)/batchsize),\n",
        "    validation_data = (valid_imgs, valid_segs),\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping, model_checkpoint, reduce_lr],\n",
        "    initial_epoch=0,\n",
        "    epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "203/203 [==============================] - 79s 389ms/step - loss: 0.1284 - acc: 0.8932 - val_loss: 0.0873 - val_acc: 0.9373\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.08725, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 2/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0781 - acc: 0.9409 - val_loss: 0.0725 - val_acc: 0.9478\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.08725 to 0.07254, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 3/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0703 - acc: 0.9452 - val_loss: 0.0659 - val_acc: 0.9509\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.07254 to 0.06594, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 4/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0667 - acc: 0.9473 - val_loss: 0.0603 - val_acc: 0.9539\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.06594 to 0.06031, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 5/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0645 - acc: 0.9487 - val_loss: 0.0580 - val_acc: 0.9545\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.06031 to 0.05795, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 6/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0628 - acc: 0.9498 - val_loss: 0.0561 - val_acc: 0.9555\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.05795 to 0.05614, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 7/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0615 - acc: 0.9506 - val_loss: 0.0546 - val_acc: 0.9555\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.05614 to 0.05463, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 8/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0606 - acc: 0.9511 - val_loss: 0.0535 - val_acc: 0.9558\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.05463 to 0.05351, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 9/100\n",
            "203/203 [==============================] - 70s 343ms/step - loss: 0.0596 - acc: 0.9518 - val_loss: 0.0523 - val_acc: 0.9566\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.05351 to 0.05234, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 10/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0588 - acc: 0.9523 - val_loss: 0.0519 - val_acc: 0.9570\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.05234 to 0.05186, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 11/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0581 - acc: 0.9527 - val_loss: 0.0517 - val_acc: 0.9566\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.05186 to 0.05169, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 12/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0573 - acc: 0.9532 - val_loss: 0.0504 - val_acc: 0.9576\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.05169 to 0.05039, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 13/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0568 - acc: 0.9534 - val_loss: 0.0497 - val_acc: 0.9576\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.05039 to 0.04975, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 14/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0561 - acc: 0.9538 - val_loss: 0.0490 - val_acc: 0.9578\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.04975 to 0.04899, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 15/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0557 - acc: 0.9541 - val_loss: 0.0488 - val_acc: 0.9582\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.04899 to 0.04880, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 16/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0552 - acc: 0.9543 - val_loss: 0.0498 - val_acc: 0.9585\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.04880\n",
            "Epoch 17/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0548 - acc: 0.9546 - val_loss: 0.0481 - val_acc: 0.9574\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.04880 to 0.04815, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 18/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0546 - acc: 0.9546 - val_loss: 0.0485 - val_acc: 0.9578\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.04815\n",
            "Epoch 19/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0543 - acc: 0.9549 - val_loss: 0.0475 - val_acc: 0.9591\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.04815 to 0.04754, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 20/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0541 - acc: 0.9550 - val_loss: 0.0477 - val_acc: 0.9591\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.04754\n",
            "Epoch 21/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0536 - acc: 0.9553 - val_loss: 0.0474 - val_acc: 0.9593\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.04754 to 0.04736, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 22/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0534 - acc: 0.9554 - val_loss: 0.0485 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.04736\n",
            "Epoch 23/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0533 - acc: 0.9555 - val_loss: 0.0470 - val_acc: 0.9596\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.04736 to 0.04695, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 24/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0529 - acc: 0.9556 - val_loss: 0.0467 - val_acc: 0.9596\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.04695 to 0.04673, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 25/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0528 - acc: 0.9557 - val_loss: 0.0466 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.04673 to 0.04662, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 26/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0525 - acc: 0.9559 - val_loss: 0.0462 - val_acc: 0.9601\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.04662 to 0.04625, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 27/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0523 - acc: 0.9559 - val_loss: 0.0460 - val_acc: 0.9601\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.04625 to 0.04605, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 28/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0522 - acc: 0.9561 - val_loss: 0.0457 - val_acc: 0.9596\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.04605 to 0.04566, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 29/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0519 - acc: 0.9561 - val_loss: 0.0461 - val_acc: 0.9600\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.04566\n",
            "Epoch 30/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0518 - acc: 0.9563 - val_loss: 0.0454 - val_acc: 0.9598\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.04566 to 0.04535, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 31/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0516 - acc: 0.9564 - val_loss: 0.0456 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.04535\n",
            "Epoch 32/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0516 - acc: 0.9563 - val_loss: 0.0453 - val_acc: 0.9610\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.04535 to 0.04534, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 33/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0514 - acc: 0.9565 - val_loss: 0.0454 - val_acc: 0.9605\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.04534\n",
            "Epoch 34/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0512 - acc: 0.9565 - val_loss: 0.0445 - val_acc: 0.9609\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.04534 to 0.04451, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 35/100\n",
            "203/203 [==============================] - 70s 347ms/step - loss: 0.0511 - acc: 0.9566 - val_loss: 0.0449 - val_acc: 0.9596\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.04451\n",
            "Epoch 36/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0510 - acc: 0.9567 - val_loss: 0.0443 - val_acc: 0.9605\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.04451 to 0.04435, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 37/100\n",
            "203/203 [==============================] - 70s 343ms/step - loss: 0.0507 - acc: 0.9569 - val_loss: 0.0446 - val_acc: 0.9612\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.04435\n",
            "Epoch 38/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0507 - acc: 0.9569 - val_loss: 0.0447 - val_acc: 0.9604\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.04435\n",
            "Epoch 39/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0506 - acc: 0.9569 - val_loss: 0.0449 - val_acc: 0.9615\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.04435\n",
            "Epoch 40/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0505 - acc: 0.9570 - val_loss: 0.0444 - val_acc: 0.9615\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.04435\n",
            "Epoch 41/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0504 - acc: 0.9570 - val_loss: 0.0438 - val_acc: 0.9603\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.04435 to 0.04377, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 42/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0503 - acc: 0.9571 - val_loss: 0.0439 - val_acc: 0.9611\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.04377\n",
            "Epoch 43/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0502 - acc: 0.9572 - val_loss: 0.0440 - val_acc: 0.9614\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.04377\n",
            "Epoch 44/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0501 - acc: 0.9572 - val_loss: 0.0434 - val_acc: 0.9614\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.04377 to 0.04343, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 45/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0500 - acc: 0.9573 - val_loss: 0.0442 - val_acc: 0.9618\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.04343\n",
            "Epoch 46/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0499 - acc: 0.9573 - val_loss: 0.0444 - val_acc: 0.9620\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.04343\n",
            "Epoch 47/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0498 - acc: 0.9574 - val_loss: 0.0434 - val_acc: 0.9617\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.04343\n",
            "Epoch 48/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0498 - acc: 0.9574 - val_loss: 0.0437 - val_acc: 0.9617\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.04343\n",
            "Epoch 49/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0496 - acc: 0.9575 - val_loss: 0.0431 - val_acc: 0.9618\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.04343 to 0.04313, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 50/100\n",
            "203/203 [==============================] - 69s 342ms/step - loss: 0.0495 - acc: 0.9575 - val_loss: 0.0438 - val_acc: 0.9617\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.04313\n",
            "Epoch 51/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0496 - acc: 0.9575 - val_loss: 0.0431 - val_acc: 0.9620\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.04313 to 0.04312, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 52/100\n",
            "203/203 [==============================] - 71s 350ms/step - loss: 0.0494 - acc: 0.9576 - val_loss: 0.0438 - val_acc: 0.9615\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.04312\n",
            "Epoch 53/100\n",
            "203/203 [==============================] - 71s 347ms/step - loss: 0.0493 - acc: 0.9576 - val_loss: 0.0427 - val_acc: 0.9620\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.04312 to 0.04267, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 54/100\n",
            "203/203 [==============================] - 70s 347ms/step - loss: 0.0493 - acc: 0.9576 - val_loss: 0.0432 - val_acc: 0.9615\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.04267\n",
            "Epoch 55/100\n",
            "203/203 [==============================] - 71s 349ms/step - loss: 0.0492 - acc: 0.9576 - val_loss: 0.0430 - val_acc: 0.9622\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.04267\n",
            "Epoch 56/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0492 - acc: 0.9576 - val_loss: 0.0430 - val_acc: 0.9621\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.04267\n",
            "Epoch 57/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0491 - acc: 0.9577 - val_loss: 0.0428 - val_acc: 0.9615\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.04267\n",
            "Epoch 58/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0490 - acc: 0.9578 - val_loss: 0.0434 - val_acc: 0.9618\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.04267\n",
            "Epoch 59/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0490 - acc: 0.9578 - val_loss: 0.0432 - val_acc: 0.9625\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.04267\n",
            "Epoch 60/100\n",
            "203/203 [==============================] - 71s 348ms/step - loss: 0.0489 - acc: 0.9578 - val_loss: 0.0428 - val_acc: 0.9612\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.04267\n",
            "Epoch 61/100\n",
            "203/203 [==============================] - 70s 347ms/step - loss: 0.0488 - acc: 0.9579 - val_loss: 0.0436 - val_acc: 0.9616\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.04267\n",
            "Epoch 62/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0488 - acc: 0.9579 - val_loss: 0.0426 - val_acc: 0.9623\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.04267 to 0.04259, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 63/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0487 - acc: 0.9580 - val_loss: 0.0426 - val_acc: 0.9624\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.04259\n",
            "\n",
            "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 64/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0482 - acc: 0.9583 - val_loss: 0.0414 - val_acc: 0.9627\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.04259 to 0.04139, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 65/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0481 - acc: 0.9583 - val_loss: 0.0413 - val_acc: 0.9627\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.04139 to 0.04129, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 66/100\n",
            "203/203 [==============================] - 70s 347ms/step - loss: 0.0480 - acc: 0.9584 - val_loss: 0.0412 - val_acc: 0.9629\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.04129 to 0.04121, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 67/100\n",
            "203/203 [==============================] - 71s 348ms/step - loss: 0.0480 - acc: 0.9584 - val_loss: 0.0413 - val_acc: 0.9629\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.04121\n",
            "Epoch 68/100\n",
            "203/203 [==============================] - 70s 347ms/step - loss: 0.0480 - acc: 0.9584 - val_loss: 0.0411 - val_acc: 0.9628\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.04121 to 0.04110, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 69/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0479 - acc: 0.9585 - val_loss: 0.0411 - val_acc: 0.9627\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.04110 to 0.04105, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 70/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0479 - acc: 0.9585 - val_loss: 0.0410 - val_acc: 0.9631\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.04105 to 0.04104, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 71/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0478 - acc: 0.9585 - val_loss: 0.0410 - val_acc: 0.9629\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.04104 to 0.04098, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 72/100\n",
            "203/203 [==============================] - 70s 347ms/step - loss: 0.0479 - acc: 0.9585 - val_loss: 0.0410 - val_acc: 0.9630\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.04098\n",
            "Epoch 73/100\n",
            "203/203 [==============================] - 70s 347ms/step - loss: 0.0479 - acc: 0.9585 - val_loss: 0.0410 - val_acc: 0.9628\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.04098\n",
            "Epoch 74/100\n",
            "203/203 [==============================] - 70s 347ms/step - loss: 0.0478 - acc: 0.9585 - val_loss: 0.0409 - val_acc: 0.9629\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.04098 to 0.04087, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 75/100\n",
            "203/203 [==============================] - 70s 347ms/step - loss: 0.0478 - acc: 0.9585 - val_loss: 0.0409 - val_acc: 0.9628\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.04087\n",
            "Epoch 76/100\n",
            "203/203 [==============================] - 70s 346ms/step - loss: 0.0479 - acc: 0.9585 - val_loss: 0.0412 - val_acc: 0.9630\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.04087\n",
            "Epoch 77/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0478 - acc: 0.9585 - val_loss: 0.0409 - val_acc: 0.9629\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.04087\n",
            "Epoch 78/100\n",
            "203/203 [==============================] - 70s 345ms/step - loss: 0.0477 - acc: 0.9585 - val_loss: 0.0409 - val_acc: 0.9631\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.04087 to 0.04087, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 79/100\n",
            "203/203 [==============================] - 71s 348ms/step - loss: 0.0477 - acc: 0.9585 - val_loss: 0.0409 - val_acc: 0.9631\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.04087\n",
            "Epoch 80/100\n",
            "203/203 [==============================] - 71s 350ms/step - loss: 0.0477 - acc: 0.9586 - val_loss: 0.0409 - val_acc: 0.9631\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.04087\n",
            "Epoch 81/100\n",
            "203/203 [==============================] - 71s 349ms/step - loss: 0.0477 - acc: 0.9585 - val_loss: 0.0409 - val_acc: 0.9629\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.04087\n",
            "Epoch 82/100\n",
            "203/203 [==============================] - 71s 350ms/step - loss: 0.0477 - acc: 0.9586 - val_loss: 0.0409 - val_acc: 0.9628\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.04087\n",
            "Epoch 83/100\n",
            "203/203 [==============================] - 71s 350ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0407 - val_acc: 0.9629\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.04087 to 0.04075, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 84/100\n",
            "203/203 [==============================] - 71s 350ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0409 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.04075\n",
            "Epoch 85/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0409 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.04075\n",
            "Epoch 86/100\n",
            "203/203 [==============================] - 71s 347ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0407 - val_acc: 0.9631\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.04075 to 0.04072, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 87/100\n",
            "203/203 [==============================] - 71s 350ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0407 - val_acc: 0.9630\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.04072\n",
            "Epoch 88/100\n",
            "203/203 [==============================] - 71s 350ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0408 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.04072\n",
            "Epoch 89/100\n",
            "203/203 [==============================] - 71s 349ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0408 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.04072\n",
            "Epoch 90/100\n",
            "203/203 [==============================] - 71s 349ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0407 - val_acc: 0.9630\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.04072 to 0.04072, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 91/100\n",
            "203/203 [==============================] - 71s 350ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0408 - val_acc: 0.9633\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.04072\n",
            "Epoch 92/100\n",
            "203/203 [==============================] - 71s 348ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0407 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.04072 to 0.04071, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 93/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0476 - acc: 0.9586 - val_loss: 0.0408 - val_acc: 0.9634\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.04071\n",
            "\n",
            "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 94/100\n",
            "203/203 [==============================] - 71s 349ms/step - loss: 0.0475 - acc: 0.9587 - val_loss: 0.0407 - val_acc: 0.9631\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.04071 to 0.04065, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 95/100\n",
            "203/203 [==============================] - 71s 350ms/step - loss: 0.0475 - acc: 0.9586 - val_loss: 0.0407 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.04065\n",
            "Epoch 96/100\n",
            "203/203 [==============================] - 71s 350ms/step - loss: 0.0475 - acc: 0.9587 - val_loss: 0.0407 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.04065\n",
            "Epoch 97/100\n",
            "203/203 [==============================] - 71s 349ms/step - loss: 0.0475 - acc: 0.9587 - val_loss: 0.0406 - val_acc: 0.9631\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.04065 to 0.04063, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 98/100\n",
            "203/203 [==============================] - 71s 349ms/step - loss: 0.0475 - acc: 0.9587 - val_loss: 0.0407 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.04063\n",
            "Epoch 99/100\n",
            "203/203 [==============================] - 71s 349ms/step - loss: 0.0475 - acc: 0.9587 - val_loss: 0.0406 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.04063 to 0.04062, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n",
            "Epoch 100/100\n",
            "203/203 [==============================] - 70s 344ms/step - loss: 0.0475 - acc: 0.9587 - val_loss: 0.0406 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.04062 to 0.04060, saving model to /content/gdrive/My Drive/Retinal/training/checkpoint/keras.model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f969c3c9978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "EIRZJ-hRdn0H",
        "colab_type": "code",
        "outputId": "a0c73e6f-5106-415b-9d0d-347236a3de78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title(\"Learning curve\")\n",
        "plt.plot(model_history.history[\"loss\"], label=\"Training loss\")\n",
        "plt.plot(model_history.history[\"val_loss\"], label=\"Validation loss\")\n",
        "plt.plot( np.argmin(model_history.history[\"val_loss\"]), np.min(model_history.history[\"val_loss\"]), marker=\"*\", color=\"y\", label=\"Best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend();\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nplt.figure(figsize=(8, 8))\\nplt.title(\"Learning curve\")\\nplt.plot(model_history.history[\"loss\"], label=\"Training loss\")\\nplt.plot(model_history.history[\"val_loss\"], label=\"Validation loss\")\\nplt.plot( np.argmin(model_history.history[\"val_loss\"]), np.min(model_history.history[\"val_loss\"]), marker=\"*\", color=\"y\", label=\"Best model\")\\nplt.xlabel(\"Epochs\")\\nplt.ylabel(\"Loss\")\\nplt.legend();\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "bq7SdhMOax_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
